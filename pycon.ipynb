{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on with PyData: How to Build a Minimal Recommendation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "- About Unata\n",
    "    - What we do and what we use Python for (everything!)\n",
    "- Environment + data files check\n",
    "    - Instructions to set up a local environment and links to download handout and data files: [http://unatainc.github.io/pycon2015/](http://unatainc.github.io/pycon2015/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this tutorial\n",
    "\n",
    "### References\n",
    "Credit where credit is due. Please check the references at the bottom of this document.\n",
    "\n",
    "### Dataset\n",
    "MovieLens from GroupLens Research: [grouplens.org](http://www.grouplens.org/)\n",
    "\n",
    "The MovieLens 1M data set contains 1 million ratings collected from 6000 users\n",
    "on 4000 movies.\n",
    "\n",
    "### What this tutorial is\n",
    "\n",
    "The goal of this tutorial is to provide you with a hands-on overview of two of\n",
    "the main libraries from the scientific and data analysis communities. We're going to\n",
    "use:\n",
    "\n",
    "- numpy -- [numpy.org](http://www.numpy.org)\n",
    "- pandas -- [pandas.pydata.org](http://pandas.pydata.org/)\n",
    "\n",
    "### What this tutorial is not\n",
    "\n",
    "- An exhaustive overview of the recommendation literature\n",
    "- A set of recipes that will win you the next Netflix/Kaggle/etc challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "What exactly are we going to do? Here's a high-level overview:\n",
    "\n",
    "- quick introduction to the recommendation problem (theory)\n",
    "- learn about Pandas Series and DataFrames (practice) \n",
    "- known solutions & challenges to the recommendation problem (theory) \n",
    "- load data, setup evaluation functions, test dummy solution (practice) \n",
    "- minimal reco engine v1.0 (practice) \n",
    "- more formulas! (theory) \n",
    "- pandas aggregation & minimal reco engine v1.1 (practice) \n",
    "- challenge (practice) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recommendation Problem\n",
    "\n",
    "Recommenders have been around since at least 1992. Today we see different flavours of recommenders, deployed across different verticals: \n",
    "\n",
    "- Amazon\n",
    "- Netflix\n",
    "- Facebook\n",
    "- Last.fm.\n",
    "\n",
    "What exactly do they do?\n",
    "\n",
    "### Definitions from the literature\n",
    "\n",
    "- *In a typical recommender system people provide recommendations as inputs, which\n",
    "the system then aggregates and directs to appropriate recipients.* -- Resnick\n",
    "and Varian, 1997\n",
    "\n",
    "- *Collaborative filtering simply means that people collaborate to help one\n",
    "another perform filtering by recording their reactions to documents they read.*\n",
    "-- Goldberg et al, 1992\n",
    "\n",
    "- *In its most common formulation, the recommendation problem is reduced to the\n",
    "problem of estimating ratings for the items that have not been seen by a\n",
    "user. Intuitively, this estimation is usually based on the ratings given by this\n",
    "user to other items and on some other information [...] Once we can estimate\n",
    "ratings for the yet unrated items, we can recommend to the user the item(s) with\n",
    "the highest estimated rating(s).* -- Adomavicius and Tuzhilin, 2005\n",
    "\n",
    "- *Driven by computer algorithms, recommenders help consumers\n",
    "by selecting products they will probably like and might buy\n",
    "based on their browsing, searches, purchases, and preferences.* -- Konstan and Riedl, 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "- $U$ is the set of users in our domain. Its size is $|U|$.\n",
    "- $I$ is the set of items in our domain. Its size is $|I|$.\n",
    "- $I(u)$ is the set of items that user $u$ has rated.\n",
    "- $-I(u)$ is the complement of $I(u)$ i.e., the set of items not yet seen by user $u$.\n",
    "- $U(i)$ is the set of users that have rated item $i$.\n",
    "- $-U(i)$ is the complement of $U(i)$.\n",
    "- $S(u,i)$ is a function that measures the utility of item $i$ for user $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal of a recommendation system\n",
    "\n",
    "$\n",
    "i^{*} = argmax_{i \\in -I(u)} S(u,i), \\forall{u \\in U}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "The recommendation problem in its most basic form is quite simple to define:\n",
    "\n",
    "```\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| user_id, movie_id | m_1 | m_2 | m_3 | m_4 | m_5 |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_1               | ?   | ?   | 4   | ?   | 1   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_2               | 3   | ?   | ?   | 2   | 2   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_3               | 3   | ?   | ?   | ?   | ?   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_4               | ?   | 1   | 2   | 1   | 1   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_5               | ?   | ?   | ?   | ?   | ?   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_6               | 2   | ?   | 2   | ?   | ?   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_7               | ?   | ?   | ?   | ?   | ?   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_8               | 3   | 1   | 5   | ?   | ?   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "| u_9               | ?   | ?   | ?   | ?   | 2   |\n",
    "|-------------------+-----+-----+-----+-----+-----|\n",
    "```\n",
    "\n",
    "*Given a partially filled matrix of ratings ($|U|x|I|$), estimate the missing values.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas: Python Data Analysis Library\n",
    "\n",
    "### What is it?\n",
    "\n",
    "*Python has long been great for data munging and preparation, but less so for\n",
    "data analysis and modeling. pandas helps fill this gap, enabling you to carry\n",
    "out your entire data analysis workflow in Python without having to switch to a\n",
    "more domain specific language like R.*\n",
    "\n",
    "The heart of pandas is the DataFrame object for data manipulation. It features:\n",
    "\n",
    "- a powerful index object\n",
    "- data alignment\n",
    "- handling of missing data\n",
    "- aggregation with groupby\n",
    "- data manipuation via reshape, pivot, slice, merge, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set some print options\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(threshold=5)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('precision', 3, 'notebook_repr_html', True, )\n",
    "\n",
    "# init random gen\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series: labelled arrays\n",
    "\n",
    "The pandas Series is kind of like an ndarray (used to actually be a subclass of it) that supports more meaninful indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at some creation examples for Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     2.00\n1     1.00\n2     5.00\n3     0.97\n4     3.00\n5    10.00\n6     0.06\n7     8.00\ndtype: float64"
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2.0, 1.0, 5.0, 0.97, 3.0, 10.0, 0.06, 8.0])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "A     2.00\nB     1.00\nC     5.00\nD     0.97\nE     3.00\nF    10.00\nG     0.06\nH     8.00\ndtype: float64"
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.array([2.0, 1.0, 5.0, 0.97, 3.0, 10.0, 0.0599, 8.0])\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "ser = pd.Series(data=values, index=labels)\n",
    "ser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                                                1\n",
      "gender                                             F\n",
      "genres                                         Drama\n",
      "movie_id                                        1193\n",
      "occupation                                        10\n",
      "rating                                             5\n",
      "timestamp                                  978300760\n",
      "title         One Flew Over the Cuckoo's Nest (1975)\n",
      "user_id                                            1\n",
      "zip                                            48067\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "movie_rating = {\n",
    "    'age': 1,\n",
    "    'gender': 'F',\n",
    "    'genres': 'Drama',\n",
    "    'movie_id': 1193,\n",
    "    'occupation': 10,\n",
    "    'rating': 5,\n",
    "    'timestamp': 978300760,\n",
    "    'title': \"One Flew Over the Cuckoo's Nest (1975)\",\n",
    "    'user_id': 1,\n",
    "    'zip': '48067'\n",
    "    }\n",
    "ser = pd.Series(movie_rating)\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['age', 'gender', 'genres', 'movie_id', 'occupation', 'rating',\n       'timestamp', 'title', 'user_id', 'zip'],\n      dtype='object')"
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 'F', 'Drama', ..., \"One Flew Over the Cuckoo's Nest (1975)\", 1,\n       '48067'], dtype=object)"
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'F'"
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.loc['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gender        F\nzip       48067\ndtype: object"
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.loc[['gender', 'zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([False, False, False, ..., False, False, False])"
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booleans = np.array([False, False, False, False, False, True, False, False, False, False])\n",
    "booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "rating    5\ndtype: object"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.loc[booleans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'F'"
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gender        F\ngenres    Drama\ndtype: object"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.iloc[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'F'"
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.loc['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'F'"
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'F'"
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gender        F\ngenres    Drama\ndtype: object"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser[[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations between Series with different index objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    6.0\n",
      "B    NaN\n",
      "C    9.0\n",
      "G    NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser_1 = pd.Series(data=[1,3,4], index=['A', 'B', 'C'])\n",
    "ser_2 = pd.Series(data=[5,5,5], index=['A', 'G', 'C'])\n",
    "print(ser_1 + ser_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic upcasting when performing operations between Series with different dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "A    6.0\nB    NaN\nC    9.0\nG    NaN\ndtype: float64"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_1 = pd.Series(data=[1,3,4], index=['A', 'B', 'C'], dtype='int')\n",
    "ser_2 = pd.Series(data=[5,5,5], index=['A', 'G', 'C'], dtype='float')\n",
    "ser_1 + ser_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "The DataFrame is the 2-dimensional version of a Series.\n",
    "\n",
    "#### Let's look at some creation examples for DataFrame\n",
    "\n",
    "You can think of it as a spreadsheet whose columns are Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   col_1  col_2\n0   0.12    0.9\n1   7.00    9.0\n2  45.00   34.0\n3  10.00   11.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_1</th>\n      <th>col_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.12</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.00</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45.00</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.00</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build from a dict of equal-length lists or ndarrays\n",
    "pd.DataFrame({'col_1': [0.12, 7, 45, 10], 'col_2': [0.9, 9, 34, 11]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explicitly set the column names and index values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   col_1  col_2 col_3\n0   0.12    0.9   NaN\n1   7.00    9.0   NaN\n2  45.00   34.0   NaN\n3  10.00   11.0   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_1</th>\n      <th>col_2</th>\n      <th>col_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.12</td>\n      <td>0.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.00</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45.00</td>\n      <td>34.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.00</td>\n      <td>11.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'col_1': [0.12, 7, 45, 10], 'col_2': [0.9, 9, 34, 11]},\n",
    "             columns=['col_1', 'col_2', 'col_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      col_1  col_2 col_3\nobs1   0.12    0.9   NaN\nobs2   7.00    9.0   NaN\nobs3  45.00   34.0   NaN\nobs4  10.00   11.0   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_1</th>\n      <th>col_2</th>\n      <th>col_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>obs1</th>\n      <td>0.12</td>\n      <td>0.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>obs2</th>\n      <td>7.00</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>obs3</th>\n      <td>45.00</td>\n      <td>34.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>obs4</th>\n      <td>10.00</td>\n      <td>11.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'col_1': [0.12, 7, 45, 10], 'col_2': [0.9, 9, 34, 11]},\n",
    "             columns=['col_1', 'col_2', 'col_3'],\n",
    "             index=['obs1', 'obs2', 'obs3', 'obs4'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also think of it as a dictionary of Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "rating_events        r_1        r_2\nrating_data                        \ngender                 F          F\ngenres             Drama      Drama\nmovie_id            1193       1193\nrating                 5          5\ntimestamp      978300760  978300760\nuser_id                1          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>rating_events</th>\n      <th>r_1</th>\n      <th>r_2</th>\n    </tr>\n    <tr>\n      <th>rating_data</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gender</th>\n      <td>F</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>genres</th>\n      <td>Drama</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>movie_id</th>\n      <td>1193</td>\n      <td>1193</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <td>978300760</td>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating = {\n",
    "    'gender': 'F',\n",
    "    'genres': 'Drama',\n",
    "    'movie_id': 1193,\n",
    "    'rating': 5,\n",
    "    'timestamp': 978300760,\n",
    "    'user_id': 1,\n",
    "    }\n",
    "ser_1 = pd.Series(movie_rating)\n",
    "ser_2 = pd.Series(movie_rating)\n",
    "df = pd.DataFrame({'r_1': ser_1, 'r_2': ser_2})\n",
    "df.columns.name = 'rating_events'\n",
    "df.index.name = 'rating_data'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "rating_data   gender genres movie_id rating  timestamp user_id\nrating_events                                                 \nr_1                F  Drama     1193      5  978300760       1\nr_2                F  Drama     1193      5  978300760       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>rating_data</th>\n      <th>gender</th>\n      <th>genres</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n    </tr>\n    <tr>\n      <th>rating_events</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>r_1</th>\n      <td>F</td>\n      <td>Drama</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978300760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>r_2</th>\n      <td>F</td>\n      <td>Drama</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978300760</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['gender', 'genres', 'movie_id', 'rating', 'timestamp', 'user_id'], dtype='object', name='rating_data')"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['r_1', 'r_2'], dtype='object', name='rating_events')"
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([['F', 'Drama', 1193, 5, 978300760, 1],\n       ['F', 'Drama', 1193, 5, 978300760, 1]], dtype=object)"
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding/Deleting entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 r_1        r_2\ngender             F          F\nmovie_id        1193       1193\nrating             5          5\ntimestamp  978300760  978300760\nuser_id            1          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r_1</th>\n      <th>r_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gender</th>\n      <td>F</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>movie_id</th>\n      <td>1193</td>\n      <td>1193</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <td>978300760</td>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'r_1': ser_1, 'r_2': ser_2})\n",
    "df.drop('genres', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 r_2\ngender             F\ngenres         Drama\nmovie_id        1193\nrating             5\ntimestamp  978300760\nuser_id            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gender</th>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>genres</th>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>movie_id</th>\n      <td>1193</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('r_1', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new column using dictionary notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 r_1        r_2        r_3\ngender             F          F          F\ngenres         Drama      Drama      Drama\nmovie_id        1193       1193       1193\nrating             5          5          5\ntimestamp  978300760  978300760  978300760\nuser_id            1          1          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r_1</th>\n      <th>r_2</th>\n      <th>r_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gender</th>\n      <td>F</td>\n      <td>F</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>genres</th>\n      <td>Drama</td>\n      <td>Drama</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>movie_id</th>\n      <td>1193</td>\n      <td>1193</td>\n      <td>1193</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <td>978300760</td>\n      <td>978300760</td>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# careful with the order here\n",
    "df['r_3'] = ['F', 'Drama', 1193, 5, 978300760, 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 r_1        r_2        r_3  r_4\ngender             F          F          F    M\ngenres         Drama      Drama      Drama  NaN\nmovie_id        1193       1193       1193  NaN\nrating             5          5          5  NaN\ntimestamp  978300760  978300760  978300760  NaN\nuser_id            1          1          1  NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r_1</th>\n      <th>r_2</th>\n      <th>r_3</th>\n      <th>r_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gender</th>\n      <td>F</td>\n      <td>F</td>\n      <td>F</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>genres</th>\n      <td>Drama</td>\n      <td>Drama</td>\n      <td>Drama</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>movie_id</th>\n      <td>1193</td>\n      <td>1193</td>\n      <td>1193</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <td>978300760</td>\n      <td>978300760</td>\n      <td>978300760</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['r_4'] = pd.Series({'gender': 'M'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Go to \"Pandas questions: Series and DataFrames\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index into a column using it's label, or with dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      col_1  col_2 col_3\nobs1   0.12    0.9   NaN\nobs2   7.00    9.0   NaN\nobs3  45.00   34.0   NaN\nobs4  10.00   11.0   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_1</th>\n      <th>col_2</th>\n      <th>col_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>obs1</th>\n      <td>0.12</td>\n      <td>0.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>obs2</th>\n      <td>7.00</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>obs3</th>\n      <td>45.00</td>\n      <td>34.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>obs4</th>\n      <td>10.00</td>\n      <td>11.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'col_1': [0.12, 7, 45, 10], 'col_2': [0.9, 9, 34, 11]},\n",
    "                  columns=['col_1', 'col_2', 'col_3'],\n",
    "                  index=['obs1', 'obs2', 'obs3', 'obs4'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "obs1     0.12\nobs2     7.00\nobs3    45.00\nobs4    10.00\nName: col_1, dtype: float64"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['col_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "obs1     0.12\nobs2     7.00\nobs3    45.00\nobs4    10.00\nName: col_1, dtype: float64"
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.col_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use multiple columns to select a subset of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      col_2  col_1\nobs1    0.9   0.12\nobs2    9.0   7.00\nobs3   34.0  45.00\nobs4   11.0  10.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_2</th>\n      <th>col_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>obs1</th>\n      <td>0.9</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>obs2</th>\n      <td>9.0</td>\n      <td>7.00</td>\n    </tr>\n    <tr>\n      <th>obs3</th>\n      <td>34.0</td>\n      <td>45.00</td>\n    </tr>\n    <tr>\n      <th>obs4</th>\n      <td>11.0</td>\n      <td>10.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['col_2', 'col_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame has similar .loc and .iloc methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.12"
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['obs1', 'col_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.12"
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Go to \"Pandas questions: Indexing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MovieLens dataset: loading and first look\n",
    "\n",
    "Loading of the MovieLens dataset is based on the intro chapter of 'Python\n",
    "for Data Analysis\".\n",
    "\n",
    "The MovieLens data is spread across three files. We'll load each file using the `pd.read_table` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  movie_id  rating  timestamp\n0        1      1193       5  978300760\n1        1       661       3  978302109\n2        1       914       3  978301968\n3        1      3408       4  978300275\n4        1      2355       5  978824291",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>661</td>\n      <td>3</td>\n      <td>978302109</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>914</td>\n      <td>3</td>\n      <td>978301968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3408</td>\n      <td>4</td>\n      <td>978300275</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2355</td>\n      <td>5</td>\n      <td>978824291</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_table('data/ml-1m/users.dat',\n",
    "                      sep='::', header=None, \n",
    "                      names=['user_id', 'gender', 'age', 'occupation', 'zip'], engine='python')\n",
    "\n",
    "ratings = pd.read_table('data/ml-1m/ratings.dat',\n",
    "                        sep='::', header=None, \n",
    "                        names=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')\n",
    "\n",
    "movies = pd.read_table('data/ml-1m/movies.dat',\n",
    "                       sep='::', header=None, \n",
    "                       names=['movie_id', 'title', 'genres'], engine='python')\n",
    "\n",
    "# show how one of them looks\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pd.merge` we get it all into  one big DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  movie_id  rating  timestamp gender  age  occupation    zip  \\\n0        1      1193       5  978300760      F    1          10  48067   \n1        2      1193       5  978298413      M   56          16  70072   \n2       12      1193       4  978220179      M   25          12  32793   \n3       15      1193       4  978199279      M   25           7  22903   \n4       17      1193       5  978158471      M   50           1  95350   \n\n                                    title genres  \n0  One Flew Over the Cuckoo's Nest (1975)  Drama  \n1  One Flew Over the Cuckoo's Nest (1975)  Drama  \n2  One Flew Over the Cuckoo's Nest (1975)  Drama  \n3  One Flew Over the Cuckoo's Nest (1975)  Drama  \n4  One Flew Over the Cuckoo's Nest (1975)  Drama  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>occupation</th>\n      <th>zip</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978300760</td>\n      <td>F</td>\n      <td>1</td>\n      <td>10</td>\n      <td>48067</td>\n      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978298413</td>\n      <td>M</td>\n      <td>56</td>\n      <td>16</td>\n      <td>70072</td>\n      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>1193</td>\n      <td>4</td>\n      <td>978220179</td>\n      <td>M</td>\n      <td>25</td>\n      <td>12</td>\n      <td>32793</td>\n      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1193</td>\n      <td>4</td>\n      <td>978199279</td>\n      <td>M</td>\n      <td>25</td>\n      <td>7</td>\n      <td>22903</td>\n      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978158471</td>\n      <td>M</td>\n      <td>50</td>\n      <td>1</td>\n      <td>95350</td>\n      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n      <td>Drama</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens = pd.merge(pd.merge(ratings, users), movies)\n",
    "movielens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge prep: evaluation mechanism\n",
    "\n",
    "Before we start building our minimal reco engine we need a basic mechanism to evaluate the performance of our engine. For that we will:\n",
    "\n",
    "- split the data into train and test sets\n",
    "- introduce a performance criterion\n",
    "- write an `evaluate` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: split ratings into train and test sets\n",
    "\n",
    "This subsection will generate training and testing sets for evaluation. You do\n",
    "not need to understand every single line of code, just the general gist:\n",
    "\n",
    "- take a smaller sample from the full 1M dataset for speed reasons;\n",
    "- make sure that we have at least 2 ratings per user in that subset;\n",
    "- split the result into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "3698\n",
      "2275\n"
     ]
    }
   ],
   "source": [
    "# let's work with a smaller subset for speed reasons\n",
    "movielens = movielens.iloc[np.random.choice(movielens.index, size=10000, replace=False)]\n",
    "print(movielens.shape)\n",
    "print(movielens.user_id.nunique())\n",
    "print(movielens.movie_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ids_larger_1 = pd.value_counts(movielens.user_id, sort=False) > 1\n",
    "user_ids_larger_1 = user_ids_larger_1[user_ids_larger_1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-353-8a728f272e68>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Original code from tutorial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmovielens\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmovielens\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0ml\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mmovielens\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ml\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'user_id'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32min\u001B[0m \u001B[0muser_ids_larger_1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmovielens\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32massert\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmovielens\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muser_id\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue_counts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5463\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5464\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5465\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5466\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5467\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "# Original code from tutorial\n",
    "movielens = movielens.select(lambda l: movielens.loc[l, 'user_id'] in user_ids_larger_1)\n",
    "print(movielens.shape)\n",
    "assert np.all(movielens.user_id.value_counts() > 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 10)\n"
     ]
    }
   ],
   "source": [
    "# Attempted to fix for AttributeError\n",
    "movielens_attempt_fix = movielens.iloc[user_ids_larger_1]\n",
    "print(movielens_attempt_fix.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-343-f52aa68e835c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32massert\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmovielens_attempt_fix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muser_id\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue_counts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "assert np.all(movielens_attempt_fix.user_id.value_counts() > 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate train and test subsets by marking 20% of each users's ratings, using groupby and apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "(5801, 11)\n",
      "(4199, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-344-2824d7d87eb9>:15: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  assert len(movielens_train.index & movielens_test.index) == 0\n"
     ]
    }
   ],
   "source": [
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    # changed ix\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "movielens['for_testing'] = False\n",
    "grouped = movielens.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "movielens_train = movielens[grouped.for_testing == False]\n",
    "movielens_test = movielens[grouped.for_testing == True]\n",
    "print(movielens.shape)\n",
    "print(movielens_train.shape)\n",
    "print(movielens_test.shape)\n",
    "assert len(movielens_train.index & movielens_test.index) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store these two sets in text files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movielens_train.to_csv('data/my_generated_movielens_train.csv')\n",
    "movielens_test.to_csv('data/my_generated_movielens_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: performance criterion\n",
    "\n",
    "Performance evaluation of recommendation systems is an entire topic all in\n",
    "itself. Some of the options include:\n",
    "\n",
    "- RMSE: $\\sqrt{\\frac{\\sum(\\hat y - y)^2}{n}}$\n",
    "- Precision / Recall / F-scores\n",
    "- ROC curves\n",
    "- Cost curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    \n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: the 'evaluate' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(estimate_f):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    \n",
    "    ids_to_estimate = zip(movielens_test.user_id, movielens_test.movie_id)\n",
    "    estimated = np.array([estimate_f(u,i) for (u,i) in ids_to_estimate])\n",
    "    real = movielens_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_estimate_function(user_id, movie_id):\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for my estimate function: 1.2962106091680619\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for my estimate function: %s' % evaluate(my_estimate_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Go to \"Mini Challenge prep: data loading & evaluation functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well-known Solutions to the Recommendation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "\n",
    "*Recommend based on the user's rating history.* \n",
    "\n",
    "Generic expression (notice how this is kind of a 'row-based' approach):\n",
    "\n",
    "$$ \\newcommand{\\aggr}{\\mathop{\\rm aggr}\\nolimits}r_{u,i} = \\aggr_{i' \\in I(u)} [r_{u,i'}]$$\n",
    "\n",
    "\n",
    "A simple example using the mean as an aggregation function:\n",
    "\n",
    "$$ r_{u,i} = \\bar r_u = \\frac{\\sum_{i' \\in I(u)} r_{u,i'}}{|I(u)|} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering\n",
    "\n",
    "*Recommend based on other user's rating histories.* \n",
    "\n",
    "Generic expression (notice how this is kind of a 'col-based' approach):\n",
    "\n",
    "$$ \\newcommand{\\aggr}{\\mathop{\\rm aggr}\\nolimits}r_{u,i} = \\aggr_{u' \\in U(i)} [r_{u',i}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example using the mean as an aggregation function:\n",
    "\n",
    "$$ r_{u,i} = \\bar r_i = \\frac{\\sum_{u' \\in U(i)} r_{u',i}}{|U(i)|} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid solutions\n",
    "\n",
    "The literature has lots of examples of systems that try to combine the strengths\n",
    "of the two main approaches. This can be done in a number of ways:\n",
    "\n",
    "- Combine the predictions of a content-based system and a collaborative system.\n",
    "- Incorporate content-based techniques into a collaborative approach.\n",
    "- Incorporarte collaborative techniques into a content-based approach.\n",
    "- Unifying model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "\n",
    "#### Availability of item metadata\n",
    "\n",
    "Content-based techniques are limited by the amount of metadata that is available\n",
    "to describe an item. There are domains in which feature extraction methods are\n",
    "expensive or time consuming, e.g., processing multimedia data such as graphics,\n",
    "audio/video streams. In the context of grocery items for example, it's often the\n",
    "case that item information is only partial or completely missing. Examples\n",
    "include:\n",
    "\n",
    "- Ingredients\n",
    "- Nutrition facts\n",
    "- Brand\n",
    "- Description\n",
    "- County of origin\n",
    "\n",
    "#### New user problem\n",
    "\n",
    "A user has to have rated a sufficient number of items before a recommender\n",
    "system can have a good idea of what their preferences are. In a content-based\n",
    "system, the aggregation function needs ratings to aggregate.\n",
    "\n",
    "#### New item problem\n",
    "\n",
    "Collaborative filters rely on an item being rated by many users to compute\n",
    "aggregates of those ratings. Think of this as the exact counterpart of the new\n",
    "user problem for content-based systems.\n",
    "\n",
    "#### Data sparsity\n",
    "\n",
    "When looking at the more general versions of content-based and collaborative\n",
    "systems, the success of the recommender system depends on the availability of a\n",
    "critical mass of user/item iteractions. We get a first glance at the data\n",
    "sparsity problem by quantifying the ratio of existing ratings vs $|U|x|I|$. A\n",
    "highly sparse matrix of interactions makes it difficult to compute similarities\n",
    "between users and items. As an example, for a user whose tastes are unusual\n",
    "compared to the rest of the population, there will not be any other users who\n",
    "are particularly similar, leading to poor recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal reco engine v1.0: simple mean ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering using mean ratings\n",
    "\n",
    "With this table-like representation of the ratings data, a basic content-based\n",
    "filter becomes a one-liner function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for estimate1: nan\n"
     ]
    }
   ],
   "source": [
    "#TODO Fix nan estimate. Expect this to happen when the errors above are resolved.\n",
    "\n",
    "def content_mean(user_id, movie_id):\n",
    "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
    "    \n",
    "    user_condition = movielens_train.user_id == user_id\n",
    "    return movielens_train.loc[user_condition, 'rating'].mean()\n",
    "\n",
    "print('RMSE for estimate1: %s' % evaluate(content_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Go to \"Reco systems questions: Minimal reco engine v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More formulas!\n",
    "\n",
    "Here are some basic ways in which we can generalize the simple mean-based algorithms we discussed before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizations of the aggregation function for content-based filtering: incorporating similarities\n",
    "\n",
    "Possibly incorporating metadata about items, which makes the term 'content' make more sense now.\n",
    "\n",
    "$$ r_{u,i} = k \\sum_{i' \\in I(u)} sim(i, i') \\; r_{u,i'} $$\n",
    "\n",
    "$$ r_{u,i} = \\bar r_u + k \\sum_{i' \\in I(u)} sim(i, i') \\; (r_{u,i'} - \\bar r_u) $$\n",
    "\n",
    "Here $k$ is a normalizing factor,\n",
    "\n",
    "$$ k = \\frac{1}{\\sum_{i' \\in I(u)} |sim(i,i')|} $$\n",
    "\n",
    "and $\\bar r_u$ is the average rating of user u:\n",
    "\n",
    "$$ \\bar r_u = \\frac{\\sum_{i \\in I(u)} r_{u,i}}{|I(u)|} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizations of the aggregation function for collaborative filtering: incorporating similarities\n",
    "\n",
    "Possibly incorporating metadata about users.\n",
    "\n",
    "$$ r_{u,i} = k \\sum_{u' \\in U(i)} sim(u, u') \\; r_{u',i} $$\n",
    "\n",
    "$$ r_{u,i} = \\bar r_u + k \\sum_{u' \\in U(i)} sim(u, u') \\; (r_{u',i} - \\bar r_u) $$\n",
    "\n",
    "Here $k$ is a normalizing factor,\n",
    "\n",
    "$$ k = \\frac{1}{\\sum_{u' \\in U(i)} |sim(u,u')|} $$\n",
    "\n",
    "and $\\bar r_u$ is the average rating of user u:\n",
    "\n",
    "$$ \\bar r_u = \\frac{\\sum_{i \\in I(u)} r_{u,i}}{|I(u)|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "\n",
    "The idea of groupby is that of *split-apply-combine*:\n",
    "\n",
    "- split data in an object according to a given key;\n",
    "- apply a function to each subset;\n",
    "- combine results into a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gender\nF    3.610\nM    3.485\nName: rating, dtype: float64"
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_train.groupby('gender')['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gender  age\nF       1      4.000\n        18     3.500\n        25     3.727\n        35     3.548\n        45     3.357\n        50     3.778\n        56     5.000\nM       1      3.833\n        18     3.133\n        25     3.474\n        35     3.558\n        45     3.775\n        50     3.481\n        56     4.167\nName: rating, dtype: float64"
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_train.groupby(['gender', 'age'])['rating'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "Let's start with a simple pivoting example that does not involve any\n",
    "aggregation. We can extract a ratings matrix as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "movie_id  1     3     5     14    22    25    26    32    34    44    ...  \\\nuser_id                                                               ...   \n18         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n45         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n59         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n\nmovie_id  3844  3849  3852  3863  3865  3873  3877  3893  3911  3927  \nuser_id                                                               \n18         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n45         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n59         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n\n[3 rows x 525 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>movie_id</th>\n      <th>1</th>\n      <th>3</th>\n      <th>5</th>\n      <th>14</th>\n      <th>22</th>\n      <th>25</th>\n      <th>26</th>\n      <th>32</th>\n      <th>34</th>\n      <th>44</th>\n      <th>...</th>\n      <th>3844</th>\n      <th>3849</th>\n      <th>3852</th>\n      <th>3863</th>\n      <th>3865</th>\n      <th>3873</th>\n      <th>3877</th>\n      <th>3893</th>\n      <th>3911</th>\n      <th>3927</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows  525 columns</p>\n</div>"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the ratings frame into a ratings matrix\n",
    "ratings_mtx_df = movielens_train.pivot_table(values='rating',\n",
    "                                             index='user_id',\n",
    "                                             columns='movie_id')\n",
    "ratings_mtx_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [1196, 1197, 1200]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>movie_id</th>\n      <th>1196</th>\n      <th>1197</th>\n      <th>1200</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab another sub-square of the ratings matrix to actually display some real entries!\n",
    "ratings_mtx_df.loc[11:16, 1196:1200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more interesting case with `pivot_table` is as an interface to `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gender      F      M\nage                 \n1       4.000  3.833\n18      3.500  3.133\n25      3.727  3.474\n35      3.548  3.558\n45      3.357  3.775\n50      3.778  3.481\n56      5.000  4.167",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>gender</th>\n      <th>F</th>\n      <th>M</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4.000</td>\n      <td>3.833</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3.500</td>\n      <td>3.133</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3.727</td>\n      <td>3.474</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>3.548</td>\n      <td>3.558</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3.357</td>\n      <td>3.775</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>3.778</td>\n      <td>3.481</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>5.000</td>\n      <td>4.167</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_train.pivot_table(values='rating', index='age', columns='gender', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass in a list of functions, such as `[np.mean, np.std]`, to compute mean ratings and a measure of disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         mean           std       \ngender      F      M      F      M\nage                               \n1       4.000  3.833  1.414  0.753\n18      3.500  3.133  1.171  1.166\n25      3.727  3.474  0.849  1.123\n35      3.548  3.558  1.028  1.069\n45      3.357  3.775  1.162  1.097\n50      3.778  3.481  1.302  0.975\n56      5.000  4.167    NaN  0.937",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">mean</th>\n      <th colspan=\"2\" halign=\"left\">std</th>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <th>F</th>\n      <th>M</th>\n      <th>F</th>\n      <th>M</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4.000</td>\n      <td>3.833</td>\n      <td>1.414</td>\n      <td>0.753</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3.500</td>\n      <td>3.133</td>\n      <td>1.171</td>\n      <td>1.166</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3.727</td>\n      <td>3.474</td>\n      <td>0.849</td>\n      <td>1.123</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>3.548</td>\n      <td>3.558</td>\n      <td>1.028</td>\n      <td>1.069</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3.357</td>\n      <td>3.775</td>\n      <td>1.162</td>\n      <td>1.097</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>3.778</td>\n      <td>3.481</td>\n      <td>1.302</td>\n      <td>0.975</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>5.000</td>\n      <td>4.167</td>\n      <td>NaN</td>\n      <td>0.937</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_train.pivot_table(values='rating', index='age', columns='gender', aggfunc=[np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal reco engine v1.1: implicit sim functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need a user index from the users portion of the dataset. This will allow us to retrieve information given a specific user_id in a more convenient way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        gender  age  occupation    zip\nuser_id                               \n1            F    1          10  48067\n2            M   56          16  70072\n3            M   25          15  55117\n4            M   45           7  02460\n5            M   25          20  55455",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>occupation</th>\n      <th>zip</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>1</td>\n      <td>10</td>\n      <td>48067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>56</td>\n      <td>16</td>\n      <td>70072</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>25</td>\n      <td>15</td>\n      <td>55117</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>45</td>\n      <td>7</td>\n      <td>02460</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>M</td>\n      <td>25</td>\n      <td>20</td>\n      <td>55455</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info = users.set_index('user_id')\n",
    "user_info.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in hand, we can now ask what the gender of a particular user_id is like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'M'"
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 3\n",
    "user_info.loc[user_id, 'gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative-based filtering using implicit sim functions\n",
    "\n",
    "Using the pandas aggregation framework we will build a collaborative filter that estimates ratings using an implicit `sim(u,u')` function to compare different users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for collab_gender: 1.2552000382596147\n"
     ]
    }
   ],
   "source": [
    "def collab_gender(user_id, movie_id):\n",
    "    \"\"\" Collaborative filtering using an implicit sim(u,u') based on gender. \"\"\"\n",
    "    \n",
    "    user_condition = movielens_train.user_id != user_id\n",
    "    movie_condition = movielens_train.movie_id == movie_id\n",
    "    ratings_by_others = movielens_train.loc[user_condition & movie_condition]\n",
    "    if ratings_by_others.empty: \n",
    "        return 3.0\n",
    "    \n",
    "    means_by_gender = ratings_by_others.pivot_table('rating', index='movie_id', columns='gender')\n",
    "    # changed ix 3x\n",
    "    user_gender = user_info.loc[user_id, 'gender']\n",
    "    if user_gender in means_by_gender.columns: \n",
    "        return means_by_gender.loc[movie_id, user_gender]\n",
    "    else:\n",
    "        return means_by_gender.loc[movie_id].mean()\n",
    "\n",
    "print('RMSE for collab_gender: %s' % evaluate(collab_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it seems worthwhile to write a `learn` function to pre-compute whatever datastructures we need at estimation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for CollabGenderReco: 1.2552000382596147\n"
     ]
    }
   ],
   "source": [
    "class CollabGenderReco:\n",
    "    \"\"\" Collaborative filtering using an implicit sim(u,u'). \"\"\"\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\" Prepare datastructures for estimation. \"\"\"\n",
    "        \n",
    "        self.means_by_gender = movielens_train.pivot_table('rating', index='movie_id', columns='gender')\n",
    "\n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \"\"\" Mean ratings by other users of the same gender. \"\"\"\n",
    "        \n",
    "        if movie_id not in self.means_by_gender.index: \n",
    "            return 3.0\n",
    "        \n",
    "        # changed ix 4x\n",
    "        user_gender = user_info.loc[user_id, 'gender']\n",
    "        if ~np.isnan(self.means_by_gender.loc[movie_id, user_gender]):\n",
    "            return self.means_by_gender.loc[movie_id, user_gender]\n",
    "        else:\n",
    "            return self.means_by_gender.loc[movie_id].mean()\n",
    "\n",
    "reco = CollabGenderReco()\n",
    "reco.learn()\n",
    "print('RMSE for CollabGenderReco: %s' % evaluate(reco.estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Challenge!\n",
    "\n",
    "- Not a real challenge\n",
    "- Focus on understanding the different versions of our minimal reco\n",
    "- Try to mix and match some of the ideas presented to come up with a minimal reco of your own\n",
    "- Evaluate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Challenge: first round\n",
    "Implement an `estimate` function of your own using other similarity notions, eg.:\n",
    "\n",
    "- collaborative filter based on age similarities\n",
    "- collaborative filter based on zip code similarities\n",
    "- collaborative filter based on occupation similarities\n",
    "- content filter based on movie genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal reco engine v1.2: custom similarity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few similarity functions\n",
    "\n",
    "These were all written to operate on two pandas Series, each one representing the rating history of two different users. You can also apply them to any two feature vectors that describe users or items. In all cases, the higher the return value, the more similar two Series are. You might need to add checks for edge cases, such as divisions by zero, etc.\n",
    "\n",
    "- Euclidean 'similarity'\n",
    "\n",
    "$$ sim(x,y) = \\frac{1}{1 + \\sqrt{\\sum (x - y)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclidean(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return their euclidean 'similarity'.\"\"\"\n",
    "    diff = s1 - s2\n",
    "    return 1 / (1 + np.sqrt(np.sum(diff ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cosine similarity\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x . y)}{\\sqrt{(x . x) (y . y)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cosine(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return their cosine similarity.\"\"\"\n",
    "    return np.sum(s1 * s2) / np.sqrt(np.sum(s1 ** 2) * np.sum(s2 ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson correlation\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x - \\bar x).(y - \\bar y)}{\\sqrt{(x - \\bar x).(x - \\bar x) * (y - \\bar y)(y - \\bar y)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pearson(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return a pearson correlation.\"\"\"\n",
    "    s1_c = s1 - s1.mean()\n",
    "    s2_c = s2 - s2.mean()\n",
    "    return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jaccard similarity\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x . y)}{(x . x) + (y . y) - (x . y)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jaccard(s1, s2):\n",
    "    dotp = np.sum(s1 * s2)\n",
    "    return dotp / (np.sum(s1 ** 2) + np.sum(s2 ** 2) - dotp)\n",
    "\n",
    "def binjaccard(s1, s2):\n",
    "    dotp = (s1.index & s2.index).size\n",
    "    return dotp / (s1.sum() + s2.sum() - dotp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative-based filtering using custom sim functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for CollabPearsonReco: 1.253536346770563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
      "<ipython-input-367-ef0d87ea712e>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n"
     ]
    }
   ],
   "source": [
    "#TODO Fix RuntimeWarning: invalid value encountered in double_scalars\n",
    "\n",
    "class CollabPearsonReco:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\" Prepare datastructures for estimation. \"\"\"\n",
    "        \n",
    "        self.all_user_profiles = movielens.pivot_table('rating', index='movie_id', columns='user_id')\n",
    "\n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \"\"\" Ratings weighted by correlation similarity. \"\"\"\n",
    "        \n",
    "        user_condition = movielens_train.user_id != user_id\n",
    "        movie_condition = movielens_train.movie_id == movie_id\n",
    "        ratings_by_others = movielens_train.loc[user_condition & movie_condition]\n",
    "        if ratings_by_others.empty: \n",
    "            return 3.0\n",
    "        \n",
    "        ratings_by_others.set_index('user_id', inplace=True)\n",
    "        their_ids = ratings_by_others.index\n",
    "        their_ratings = ratings_by_others.rating\n",
    "        their_profiles = self.all_user_profiles[their_ids]\n",
    "        user_profile = self.all_user_profiles[user_id]\n",
    "        sims = their_profiles.apply(lambda profile: pearson(profile, user_profile), axis=0)\n",
    "        ratings_sims = pd.DataFrame({'sim': sims, 'rating': their_ratings})\n",
    "        ratings_sims = ratings_sims[ratings_sims.sim > 0]\n",
    "        if ratings_sims.empty:\n",
    "            return their_ratings.mean()\n",
    "        else:\n",
    "            return np.average(ratings_sims.rating, weights=ratings_sims.sim)\n",
    "        \n",
    "reco = CollabPearsonReco()\n",
    "reco.learn()\n",
    "print('RMSE for CollabPearsonReco: %s' % evaluate(reco.estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Challenge: second round\n",
    "Implement an `estimate` function of your own using other custom similarity notions, eg.:\n",
    "\n",
    "- euclidean\n",
    "- cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and further reading\n",
    "\n",
    "- Goldberg, D., D. Nichols, B. M. Oki, and D. Terry. Using Collaborative Filtering to Weave an Information Tapestry. Communications of the ACM 35, no. 12 (1992): 6170.\n",
    "- Resnick, Paul, and Hal R. Varian. Recommender Systems. Commun. ACM 40, no. 3 (March 1997): 5658. doi:10.1145/245108.245121.\n",
    "- Adomavicius, Gediminas, and Alexander Tuzhilin. Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Transactions on Knowledge and Data Engineering 17, no. 6 (2005): 734749. doi:http://doi.ieeecomputersociety.org/10.1109/TKDE.2005.99.\n",
    "- Adomavicius, Gediminas, Ramesh Sankaranarayanan, Shahana Sen, and Alexander Tuzhilin. Incorporating Contextual Information in Recommender Systems Using a Multidimensional Approach. ACM Trans. Inf. Syst. 23, no. 1 (2005): 103145. doi:10.1145/1055709.1055714.\n",
    "- Koren, Y., R. Bell, and C. Volinsky. Matrix Factorization Techniques for Recommender Systems. Computer 42, no. 8 (2009): 3037.\n",
    "- William Wesley McKinney. Python for Data Analysis. OReilly, 2012.\n",
    "- Toby Segaran. Programming Collective Intelligence. OReilly, 2007.\n",
    "- Zhou, Tao, Zoltan Kuscsik, Jian-Guo Liu, Matus Medo, Joseph R Wakeling, and Yi-Cheng Zhang. Solving the Apparent Diversity-accuracy Dilemma of Recommender Systems. arXiv:0808.2670 (August 19, 2008). doi:10.1073/pnas.1000488107.\n",
    "- Shani, G., D. Heckerman, and R. I Brafman. An MDP-based Recommender System. Journal of Machine Learning Research 6, no. 2 (2006): 1265.\n",
    "- Joseph A. Konstan, John Riedl. \"Deconstructing Recommender Systems.\" IEEE Spectrum, October 2012."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cef1f773",
   "language": "python",
   "display_name": "PyCharm (pycon2015_tutorial322)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}